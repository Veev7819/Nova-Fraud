{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1a9d202-7427-4225-aec0-1d12674c154a",
   "metadata": {},
   "source": [
    "## 04_advanced_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2092e2-7aec-414e-bef0-7a6d649a9137",
   "metadata": {},
   "source": [
    "### Train XGBoost and LightGBM with imbalance handling using undersampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b82255ce-5a3a-497b-8492-49fd5c41f5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB+RUS Test ROC-AUC: 0.9793384496915475\n",
      "LGBM+RUS Test ROC-AUC: 0.974350433044637\n",
      "{\n",
      "  \"xgboost\": {\n",
      "    \"precision\": 0.7046263345195729,\n",
      "    \"recall\": 0.9473684210526315,\n",
      "    \"f1\": 0.8081632653061225,\n",
      "    \"roc_auc\": 0.9793384496915475,\n",
      "    \"threshold\": 0.5\n",
      "  },\n",
      "  \"lightgbm\": {\n",
      "    \"precision\": 0.6971830985915493,\n",
      "    \"recall\": 0.9473684210526315,\n",
      "    \"f1\": 0.8032454361054767,\n",
      "    \"roc_auc\": 0.974350433044637,\n",
      "    \"threshold\": 0.5\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "BASE = '..'\n",
    "INPUT = os.path.join(BASE, 'data', 'Nova_pay_features.csv')\n",
    "MODELS = os.path.join(BASE, 'models')\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(INPUT, parse_dates=['timestamp'])\n",
    "df = df.dropna(subset=['timestamp', 'is_fraud'])\n",
    "\n",
    "# Features\n",
    "categorical = ['home_country','source_currency','dest_currency','channel','kyc_tier','ip_country','new_device','location_mismatch', 'ip_country_missing']\n",
    "numeric = ['amount_src','amount_usd','fee','ip_risk_score','device_trust_score','account_age_days','txn_velocity_1h','txn_velocity_24h','corridor_risk','risk_score_internal', 'hour', 'dayofweek']\n",
    "for c in categorical:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(str)\n",
    "        \n",
    "df = df.sort_values('timestamp')\n",
    "max_date = df['timestamp'].max()\n",
    "valid_start = max_date - pd.Timedelta(days=270)\n",
    "test_start = max_date - pd.Timedelta(days=180)\n",
    "\n",
    "train_df = df[df['timestamp'] < valid_start]\n",
    "valid_df = df[(df['timestamp'] >= valid_start) & (df['timestamp'] < test_start)]\n",
    "test_df = df[df['timestamp'] >= test_start]\n",
    "\n",
    "X_train = train_df[categorical + numeric]\n",
    "y_train = train_df['is_fraud'].astype(int).values\n",
    "X_valid = valid_df[categorical + numeric]\n",
    "y_valid = valid_df['is_fraud'].astype(int).values\n",
    "X_test = test_df[categorical + numeric]\n",
    "y_test = test_df['is_fraud'].astype(int).values\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # One-hot econde categorical features\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical),\n",
    "\n",
    "        # Standard scale numerical features\n",
    "        (\"num\", StandardScaler(with_mean=False), numeric),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "xgb_rus = ImbPipeline(steps=[\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"rus\", rus),\n",
    "    (\"model\", XGBClassifier(\n",
    "        n_estimators=800,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric=\"aucpr\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_rus.fit(X_train, y_train)\n",
    "y_prob_xgb_rus = xgb_rus.predict_proba(X_test)[:, 1]\n",
    "print(\"XGB+RUS Test ROC-AUC:\", roc_auc_score(y_test, y_prob_xgb_rus))\n",
    "\n",
    "\n",
    "lgbm_rus = ImbPipeline(steps=[\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"rus\", rus),\n",
    "    (\"model\", LGBMClassifier(\n",
    "          n_estimators=800,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        min_child_samples=5,        \n",
    "        min_split_gain=0.0,         \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1     \n",
    "       \n",
    "    ))\n",
    "])\n",
    "\n",
    "lgbm_rus.fit(X_train, y_train)\n",
    "y_prob_lgbm_rus = lgbm_rus.predict_proba(X_test)[:, 1]\n",
    "print(\"LGBM+RUS Test ROC-AUC:\", roc_auc_score(y_test, y_prob_lgbm_rus))\n",
    "\n",
    "def metric_pack(y_true, y_prob, thr=0.5):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)\n",
    "    auc = roc_auc_score(y_true, y_prob) if len(np.unique(y_true))>1 else float('nan')\n",
    "    return {'precision': float(p), 'recall': float(r), 'f1': float(f1), 'roc_auc': float(auc), 'threshold': thr}\n",
    "\n",
    "metrics = {\n",
    "    'xgboost': metric_pack(y_test, y_prob_xgb_rus),\n",
    "    'lightgbm': metric_pack(y_test, y_prob_lgbm_rus)\n",
    "}\n",
    "\n",
    "print(json.dumps(metrics, indent=2))\n",
    "\n",
    "os.makedirs(MODELS, exist_ok=True)\n",
    "joblib.dump(xgb_rus, os.path.join(MODELS, 'model_xgb.joblib'))\n",
    "joblib.dump(lgbm_rus, os.path.join(MODELS, 'model_lgbm.joblib'))\n",
    "with open(os.path.join(MODELS, 'metrics_advanced.json'),'w',encoding='utf-8') as f:\n",
    "    json.dump(metrics, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ff6602-bf9a-4e0c-957a-fa020c86afd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pycaret310_fixed]",
   "language": "python",
   "name": "conda-env-pycaret310_fixed-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
